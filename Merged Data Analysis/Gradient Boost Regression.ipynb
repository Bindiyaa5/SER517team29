{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Function to calculate distance between two lat-lng points\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    # Difference in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'Spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'Summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_rides__with_elevation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start_Altitude'] = df[['Start_Altitude', 'Start_Altutude', 'State_Altitude']].bfill(axis=1).iloc[:, 0]\n",
    "df.drop(columns=['State_Altitude', 'Start_Altutude'], inplace=True)\n",
    "\n",
    "     \n",
    "\n",
    "df['End_Altitude'] = df[['End_Altitude', 'end_altitude', 'end_Altitude']].bfill(axis=1).iloc[:, 0]\n",
    "     \n",
    "\n",
    "df.drop(columns=['end_Altitude', 'end_altitude'], inplace=True)\n",
    "     \n",
    "\n",
    "df['Start_Altitude'].fillna(method='ffill', inplace=True)\n",
    "df['End_Altitude'].fillna(df['End_Altitude'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['Start_Altitude'] = df[['Start_Altitude', 'Start_Altutude', 'State_Altitude']].bfill(axis=1).iloc[:, 0]\n",
    "     \n",
    "\n",
    "df.drop(columns=['State_Altitude', 'Start_Altutude'], inplace=True)\n",
    "\n",
    "     \n",
    "\n",
    "df['End_Altitude'] = df[['End_Altitude', 'end_altitude', 'end_Altitude']].bfill(axis=1).iloc[:, 0]\n",
    "     \n",
    "\n",
    "df.drop(columns=['end_Altitude', 'end_altitude'], inplace=True)\n",
    "     \n",
    "\n",
    "df['Start_Altitude'].fillna(method='ffill', inplace=True)\n",
    "df['End_Altitude'].fillna(df['End_Altitude'].mean(), inplace=True)\n",
    "     \n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "df['Elevation_Change'] = df['End_Altitude'] - df['Start_Altitude']\n",
    "     \n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Elevation_Change'] = imputer.fit_transform(df[['Elevation_Change']])\n",
    "     \n",
    "\n",
    "df = df.drop(columns=['Start_Altitude', 'End_Altitude'])\n",
    "     \n",
    "\n",
    "df['Distance'] = df.apply(lambda x: haversine_distance(x['start_lat'], x['start_lng'], x['end_lat'], x['end_lng']), axis=1)\n",
    "     \n",
    "\n",
    "df = df.drop(columns=['start_lat', 'start_lng', 'end_lat', 'end_lng'])\n",
    "     \n",
    "\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season'] = df['started_at'].dt.month.map(get_season)\n",
    "     \n",
    "\n",
    "def get_day_of_week(timestamp):\n",
    "    return timestamp.strftime(\"%A\")\n",
    "     \n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "df['day_of_week'] = df['started_at'].apply(get_day_of_week)\n",
    "     \n",
    "\n",
    "df['trip_duration'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
    "     \n",
    "\n",
    "weatherData = '/content/drive/My Drive/3667056.csv'\n",
    "     \n",
    "\n",
    "tempData = pd.read_csv(weatherData)\n",
    "     \n",
    "\n",
    "tempData['started_at'] = pd.to_datetime(tempData['DATE'])\n",
    "tempData['started_at'] = tempData['started_at'].dt.date\n",
    "     \n",
    "\n",
    "df['started_at'] = df['started_at'].dt.date\n",
    "     \n",
    "\n",
    "df = pd.merge(df, tempData[['started_at', 'TMAX', 'TMIN']], on='started_at', how='left')\n",
    "     \n",
    "\n",
    "# ride_types = dfs['rideable_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(numeric_only=True), inplace=True)  # Only fill numeric columns with their means\n",
    "df.fillna('Unknown', inplace=True)\n",
    "     \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "     \n",
    "\n",
    "target_variable = 'rideable_type'\n",
    "y = df[target_variable]\n",
    "X = df.drop(target_variable, axis=1)\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':  # This identifies categorical columns\n",
    "        num_unique_values = len(X[column].unique())\n",
    "        if num_unique_values < 10:  # Limit set for one-hot encoding\n",
    "            # Apply one-hot encoding to columns with fewer unique values\n",
    "            dummies = pd.get_dummies(X[column], prefix=column)\n",
    "            X = pd.concat([X, dummies], axis=1)\n",
    "        else:\n",
    "            # Apply label encoding to columns with many unique values to save memory\n",
    "            label_encoders[column] = LabelEncoder()\n",
    "            X[column] = label_encoders[column].fit_transform(X[column].astype(str))\n",
    "        X.drop(column, axis=1, inplace=True)  # Drop original column after encoding\n",
    "     \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "     \n",
    "\n",
    "y_train_encoded = (y_train == 'electric').astype(int)  # Encode 'electric' as 1, 'classic' as 0\n",
    "y_test_encoded = (y_test == 'electric').astype(int)\n",
    "     \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "     \n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "     \n",
    "\n",
    "X_train.drop(columns=['ended_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)\n",
    "print(y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevation_Change         float64\n",
    "Distance                 float64\n",
    "trip_duration            float64\n",
    "TMAX                       int64\n",
    "TMIN                       int64\n",
    "member_casual_Unknown       bool\n",
    "member_casual_casual        bool\n",
    "member_casual_member        bool\n",
    "season_Fall                 bool\n",
    "season_Spring               bool\n",
    "season_Summer               bool\n",
    "season_Winter               bool\n",
    "day_of_week_Friday          bool\n",
    "day_of_week_Monday          bool\n",
    "day_of_week_Saturday        bool\n",
    "day_of_week_Sunday          bool\n",
    "day_of_week_Thursday        bool\n",
    "day_of_week_Tuesday         bool\n",
    "day_of_week_Wednesday       bool\n",
    "dtype: object\n",
    "2220921     1\n",
    "6189410     0\n",
    "587405      1\n",
    "10376738    0\n",
    "3510934     0\n",
    "           ..\n",
    "2234489     1\n",
    "4304572     1\n",
    "10081351    1\n",
    "6550634     1\n",
    "6423388     1\n",
    "Name: rideable_type, Length: 7971288, dtype: int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['ended_at'], inplace=True)\n",
    "     \n",
    "\n",
    "# Fit the model on the training data with encoded labels\n",
    "model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "     \n",
    "\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)  # Hyperparameters can be adjusted\n",
    "gb_regressor.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb_regressor.predict(X_test)\n",
    "     \n",
    "\n",
    "feature_importances = gb_regressor.feature_importances_\n",
    "\n",
    "     \n",
    "\n",
    "feature_names = X_train.columns\n",
    "     \n",
    "\n",
    "importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "print(importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature  Importance\n",
    "1                Distance    0.498346\n",
    "2           trip_duration    0.416795\n",
    "0        Elevation_Change    0.050170\n",
    "6    member_casual_casual    0.019550\n",
    "7    member_casual_member    0.010294\n",
    "4                    TMIN    0.002744\n",
    "3                    TMAX    0.000775\n",
    "8             season_Fall    0.000307\n",
    "10          season_Summer    0.000297\n",
    "9           season_Spring    0.000266\n",
    "12     day_of_week_Friday    0.000125\n",
    "15     day_of_week_Sunday    0.000122\n",
    "11          season_Winter    0.000104\n",
    "14   day_of_week_Saturday    0.000092\n",
    "13     day_of_week_Monday    0.000013\n",
    "5   member_casual_Unknown    0.000000\n",
    "16   day_of_week_Thursday    0.000000\n",
    "17    day_of_week_Tuesday    0.000000\n",
    "18  day_of_week_Wednesday    0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "     \n",
    "\n",
    "# Assuming gb_regressor is your trained gradient boosting regression model\n",
    "predictions = gb_regressor.predict(X_test)  # X_test is your test data\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_encoded, y_pred)\n",
    "mse = mean_squared_error(y_test_encoded, y_pred)\n",
    "rmse = mean_squared_error(y_test_encoded, y_pred, squared=False)  # RMSE\n",
    "r2 = r2_score(y_test_encoded, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error: 0.41125352854674235\n",
    "Mean Squared Error: 0.19575479960088926\n",
    "Root Mean Squared Error: 0.44244186013632264\n",
    "R-squared: 0.21649823870180052"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
