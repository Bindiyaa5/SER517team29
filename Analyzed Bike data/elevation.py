# -*- coding: utf-8 -*-
"""elevation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U-2oKm7TRwT8m-6ehpE4vp7kWV8oWsP0
"""

from google.colab import drive
drive.mount('/content/drive')

filepath = '/content/drive/My Drive/merged_rides_with_elevation.csv'

import pandas as pd
dfs = pd.read_csv(filepath)

print(dfs)

import numpy as np

# Function to calculate distance between two lat-lng points
def haversine_distance(lat1, lon1, lat2, lon2):
    # Radius of the Earth in kilometers
    R = 6371.0
    # Convert latitude and longitude from degrees to radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    # Difference in coordinates
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    # Haversine formula
    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    # Distance in kilometers
    distance = R * c
    return distance

# Apply the function to your DataFrame

dfs['rideable_type'] = dfs['rideable_type'].replace({
    'electric_bike': 'electric',
    'docked_bike': 'classic',
    'classic_bike': 'classic'
})

from sklearn.impute import SimpleImputer
dfs['Elevation_Change'] = dfs['End_Altitude'] - dfs['Start_Altitude']
# Impute the missing values in 'Elevation_Change'
imputer = SimpleImputer(strategy='mean')  # or strategy='median' if that's more appropriate
dfs['Elevation_Change'] = imputer.fit_transform(dfs[['Elevation_Change']])

# Continue with your model fitting as before

dfs = dfs.drop(columns=['end_altitude', 'end_Altitude', 'Start_Altutude', 'State_Altitude'])

# Replace missing values with some form of imputation if necessary
# For now, we'll just drop rows with NaN in 'End_Altitude'
dfs = dfs.dropna(subset=['End_Altitude'])

dfs['Distance'] = dfs.apply(lambda x: haversine_distance(x['start_lat'], x['start_lng'], x['end_lat'], x['end_lng']), axis=1)

from sklearn.impute import SimpleImputer
dfs['Elevation_Change'] = dfs['End_Altitude'] - dfs['Start_Altitude']
# Impute the missing values in 'Elevation_Change'
imputer = SimpleImputer(strategy='mean')  # or strategy='median' if that's more appropriate
dfs['Elevation_Change'] = imputer.fit_transform(dfs[['Elevation_Change']])

# Continue with your model fitting as before

import pandas as pd
import numpy as np

# Example DataFrame loading (assuming df is already loaded)
# df = pd.read_csv('your_data.csv')

# Handling missing values
# If the missing values are not significant, you might choose to fill them
dfs['Elevation_Change'] = dfs['Elevation_Change'].fillna(dfs['Elevation_Change'].mean())
dfs['Distance'] = dfs['Distance'].fillna(dfs['Distance'].mean())

# Optionally, drop rows where any crucial information is missing
dfs = dfs.dropna(subset=['rideable_type', 'Distance', 'Elevation_Change'])

from sklearn.preprocessing import StandardScaler

# Features to be scaled
features_to_scale = ['Distance', 'Elevation_Change']

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the features
dfs[features_to_scale] = scaler.fit_transform(dfs[features_to_scale])

from sklearn.model_selection import train_test_split

# Define your features and target variable
X = dfs[['Distance', 'Elevation_Change']]  # Add other features as necessary
y = dfs['rideable_type']  # Assuming 'rideable_type' is the target variable

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.model_selection import GridSearchCV

# Parameter grid
param_grid = {
    'max_depth': [10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt']
}

# Grid search with cross-validation
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2)
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
best_rf = grid_search.best_estimator_

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest model with adjusted parameters
rf_classifier = RandomForestClassifier(
    n_estimators=50,      # Reduced number of trees
    max_depth=15,         # Limiting tree depth
    max_features='sqrt',  # Limiting the number of features considered for splits
    min_samples_split=10, # Minimum number of samples required to split an internal node
    min_samples_leaf=5,   # Minimum number of samples required to be at a leaf node
    random_state=42,      # For reproducibility
    class_weight='balanced', # Handling imbalanced classes
    n_jobs=-1             # Use all cores available
)

y_pred = best_rf.predict(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Predict on the testing set
y_pred_rf = rf_classifier.predict(X_test)  # Use X_test here, not X_train

# Evaluate the model
print("Random Forest - Classification Report:")
print(classification_report(y_test, y_pred_rf))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Initialize and train the Logistic Regression model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predict on the testing set
y_pred = log_reg.predict(X_test)

# Evaluation
print("Logistic Regression - Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier

# Initialize and train the Decision Tree model
tree_model = DecisionTreeClassifier(max_depth=5)  # Limited depth to prevent overfitting
tree_model.fit(X_train, y_train)

# Predict and evaluate
y_pred_tree = tree_model.predict(X_test)
print("Decision Tree - Classification Report:")
print(classification_report(y_test, y_pred_tree))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_tree))

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_classifier.fit(X_train, y_train)

# Predict on the testing set
y_pred_rf = rf_classifier.predict(X_test)

# Evaluate the model
print("Random Forest - Classification Report:")
print(classification_report(y_test, y_pred_rf))

from sklearn.linear_model import LogisticRegression

# Initialize Logistic Regression with balanced class weights
log_reg = LogisticRegression(class_weight='balanced')
log_reg.fit(X_train, y_train)

y_pred = log_reg.predict(X_test)
print("Updated Logistic Regression - Classification Report:")
print(classification_report(y_test, y_pred))

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

log_reg = LogisticRegression(class_weight='balanced')
log_reg.fit(X_train_scaled, y_train)

y_pred_scaled = log_reg.predict(X_test_scaled)
print("Classification Report with Scaled Data:")
print(classification_report(y_test, y_pred_scaled))

from sklearn.model_selection import GridSearchCV

params = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'lbfgs']}
grid_search = GridSearchCV(LogisticRegression(class_weight='balanced'), params, cv=5)
grid_search.fit(X_train_scaled, y_train)

print("Best Parameters:", grid_search.best_params_)
y_pred_grid = grid_search.predict(X_test_scaled)
print("Classification Report with Grid Search:")
print(classification_report(y_test, y_pred_grid))

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_classifier.fit(X_train_scaled, y_train)

# Predict on the testing set
y_pred_rf = rf_classifier.predict(X_test_scaled)

# Evaluate the model
print("Random Forest - Classification Report:")
print(classification_report(y_test, y_pred_rf))



dfs['rideable_type'] = dfs['rideable_type'].replace({
    'electric_bike': 'electric',
    'docked_bike': 'classic',
    'classic_bike': 'classic'
})

# Optimize data types
for col in ['rideable_type', 'member_casual']:
    dfs[col] = dfs[col].astype('category')

# If 'Elevation_Change' has no decimal values and is within a reasonable range,
# you can convert it to a smaller integer type
dfs['Elevation_Change'] = pd.to_numeric(dfs['Elevation_Change'], downcast='float')

import gc

# Sample a fraction of the data
dfs_sample = dfs.sample(frac=0.1, random_state=1)
del dfs  # Delete the original dataframe if no longer needed
gc.collect()  # Invoke garbage collector

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt



# Encode the categorical target variable 'rideable_type'
label_encoder = LabelEncoder()
dfs_sample['rideable_type_encoded'] = label_encoder.fit_transform(dfs_sample['rideable_type'])

# Define features and target
X = dfs_sample[['Elevation_Change']]
# Ensure no NaN values in features
X  = X.fillna(X.mean())
# Features
y = dfs_sample['rideable_type_encoded']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit Logistic Regression
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predict on the testing set
y_pred = log_reg.predict(X_test)

# Evaluate the model
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Confusion matrix plot
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Predicted probabilities for the test set
y_pred_probs = log_reg.predict_proba(X_test)

# Plot of predicted probabilities
plt.hist(y_pred_probs[:, 1], bins=30, alpha=0.7, color='red', label='Predicted probabilities')
plt.xlabel('Predicted probability of electric bike')
plt.ylabel('Frequency')
plt.legend()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

# Assume 'dfs' is your DataFrame and it has been loaded and preprocessed appropriately

# First, handle NaNs before splitting into train and test sets
# Option 1: Impute NaNs (filling NaNs with the mean, median, or another statistic)
imputer = SimpleImputer(strategy='mean')  # Can use 'median' or 'most_frequent' if more appropriate
dfs_sample['Elevation_Change'] = imputer.fit_transform(dfs_sample[['Elevation_Change']])

# Option 2: Drop rows with NaNs
# This should be done only if imputation is not suitable and the number of missing values is not significant
dfs_sample = dfs_sample.dropna(subset=['Elevation_Change'])

# Now split the data into training and testing sets
X = dfs_sample[['Elevation_Change']]  # Assuming 'Elevation_Change' is your feature
y = dfs_sample['rideable_type']  # Assuming 'rideable_type' is your target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Continue with model training and evaluation

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix

models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier()
}

for name, model in models.items():
    model.fit(X_train, y_train)  # Fit the model
    y_pred = model.predict(X_test)  # Predict on the test data
    print(f"{name} Classification Report:\n{classification_report(y_test, y_pred)}")
    print(f"{name} Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}\n")

print(y_train.value_counts())
print(X_train.value_counts())

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
import numpy as np

X = dfs_sample[['Elevation_Change']]  # Add more features if available
y = dfs_sample['rideable_type']  # Target variable
X  = X.fillna(X.mean())
# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE

#Define the pipeline that includes SMOTE and a RandomForest classifier
pipeline = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(random_state=42))
])

param_grid = {
    'smote__k_neighbors': [5, 10],
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [10, 20],
    'classifier__min_samples_split': [2, 5]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

#Best model from the grid search
best_model = grid_search.best_estimator_

# Predict on test data
y_pred = best_model.predict(X_test)

# Evaluation
print("Best model parameters:", grid_search.best_params_)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# Assume these are the best parameters from your RandomForest Grid Search
best_params = {
    'max_depth': 10,
    'min_samples_split': 2,
    'n_estimators': 100
}

# Models dictionary adjusted for tree-based model parameter sharing
models = {
    'Decision Tree': DecisionTreeClassifier(max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split']),
    'Random Forest': RandomForestClassifier(**best_params),
    'SVM': SVC(probability=True),  # SVM doesn't share these hyperparameters
    'KNN': KNeighborsClassifier(),  # Neither does KNN
    'Gradient Boosting': GradientBoostingClassifier(max_depth=best_params['max_depth'], n_estimators=best_params['n_estimators'])
}

# Applying SMOTE as part of a pipeline
for name, model in models.items():
    pipeline = Pipeline([
        ('smote', SMOTE(k_neighbors=5)),  # From best grid search
        ('classifier', model)
    ])

    # Train and evaluate
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    # Print results
    print(f"Results for {name}:")
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\n")

